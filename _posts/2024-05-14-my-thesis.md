---
layout: distill
title: Reinforcement Learning-Based Model Matching in COBRA, a Slithering Snake Robot
description: A concise overview of the key ideas and findings from my thesis
giscus_comments: true
date: 2024-05-14
featured: true

bibliography: 2018-12-22-distill.bib

# Optionally, you can add a table of contents to your post.
# NOTES:
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
#   - we may want to automate TOC generation in the future using
#     jekyll-toc plugin (https://github.com/toshimaru/jekyll-toc).
toc:
  - name: Abstract
  - name: Introduction
    subsections:
      - name: Simulation-to-Reality Gap
        # subsections:
        #   - name: Example Child Subsection 1
        #   - name: Example Child Subsection 2
      - name: Motivation
      - name: Simulators and Physics Engines
  - name: COBRA Platform
  - name: Central Pattern Generators
    subsections:
      - name: Modified Kuramoto Model

# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## Abstract

This work employs a reinforcement learning-based model identification method aimed at
enhancing the accuracy of the dynamics for our snake robot, called COBRA. Leveraging gradient
information and iterative optimization, the proposed approach refines the parameters of COBRA’s
dynamical model such as coefficient of friction and actuator parameters using experimental and
simulated data. Experimental validation on the hardware platform demonstrates the efficacy of the
proposed approach, highlighting its potential to address sim-to-real gap in robot implementation.

---

## Introduction

## Simulation-to-Reality Gap

Developing effective locomotion controllers for mobile robots is challenging, and while Deep Reinforcement Learning (DRL) offers promising solutions, it requires impractical amounts of training data for high-risk tasks like locomotion and manipulation. Although computer simulations provide a safe and efficient training environment, the resulting policies often fail to transfer effectively to real hardware due to the "Simulation-to-Reality Gap" (sim2real gap), caused by discrepancies such as differences in friction, joint dynamics, and sensor noise between simulated and real environments. These discrepancies impede the transition of control policies from simulation to real-world applications, resulting in suboptimal performance and limited generalization of robotic systems.

<div class="row mt-3">
    {% include figure.liquid loading="eager" path="assets/img/sim2real_methods_new.png" class="img-fluid rounded z-depth-1" %}
</div>
<div class="caption">
    Figure 1: Popular Solutions for Solving Sim2real Problem
</div>

To tackle the challenges of the Simulation-to-Reality Gap, recent research has focused on several advanced strategies. These include employing more sophisticated system identification procedures to improve model accuracy, training policies on real robots while simultaneously enhancing simulator accuracy through domain adaptation, and developing robust control policies that can generalize across varied simulated environments through domain randomization. Although these methods have shown good transferability of learned policies from simulation to real robots, they typically require at least 1000 hours of training in the simulator and/or hundreds of rollouts on the real robot. The figure below highlights several state-of-the-art solutions addressing the sim2real problem across various robots.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/sota.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 2: Shows successful transfer of an RL-based policy on 1) ANYmal robot 2) & 6) Unitree A1 3) Hexapod 4) Cassie 5) Sirius 7) Mini Cheetah 8) 7-DoF Yumi Robot 9) & 13) ANYmal C 10) ANYmal B 11) Digit humanoid 12) Soft Snake Robot
</div>

---

## Motivation

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/research_gap.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 3: Highlights the shared aspects among the popular solutions to sim2real problem
</div>

Significant progress has been made in simulation-to-reality transfer for locomotion tasks, but several research gaps remain. There is a strong motivation to develop a framework which:

1. is data-efficient
2. is learning-based
3. is scalable
4. is modular
5. requires minimum rollouts on the real robot
6. has standardized evaluation metrics for sim2real transfer

---

## Simulators and Physics Engines

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/sim_table.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Table 1: Comparison of simulators
</div>

Table 1 compares pros and cons of most widely used physics simulators for robotics applications. After considering all the options, I chose the Webots simulator as the ideal platform for bridging the sim2real gap in training reinforcement learning (RL) agents for the COBRA platform due to its robust integration capabilities with RL training and extensive resources for developing locomotion, manipulation, and navigation controllers. Webots offers a user-friendly interface and supports various programming languages like Python and C++, simplifying the implementation and integration of RL algorithms. Its diverse library of robot models, realistic physics simulations, and advanced visualization tools create an optimal environment for training RL-based locomotion policies.

Additionally, Webots provides comprehensive tools and resources for developing controllers for various tasks essential to the COBRA platform’s functionality. Overall, Webots’ compatibility with RL training and its rich resources make it an excellent choice for addressing the sim2real gap in developing efficient controllers for the COBRA platform.

---

## COBRA Platform

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/fbd.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 4: Illustrates free body diagram of the COBRA platform
</div>

COBRA, short for Crater Observing Bio-inspired Rolling Articulator, is a snake robot inspired by the movement of serpentine creatures. Engineered to navigate rugged terrains like craters, where traditional robots may struggle, COBRA features 11 joints and 12 links, providing complex and versatile movements. Its 6 yawing and 5 pitching joints allow a wide range of orientations, making it suitable for diverse robotic applications. Figure 4 shows a free body diagram of COBRA and its ground friction coefficients. The ground contact model used in the simulator is given below:

$$
F_{GRF} = 
\begin{cases}
    0,                                & \text{if } p_{C,z} > 0\\
    [F_{GRF,x},F_{GRF,y},F_{GRF,z}]^T,& \text{otherwise}
\end{cases}
$$

$$
F_{GRF,i} = - s_{i} F_{GRF,z} \, \mathrm{sgn}(\dot p_{C,i}) - \mu_v \dot p_{C,i} ~~  \mbox{if} ~~i=x, y
$$

$$
F_{GRF,z} = -k_1 p_{C,z} - k_{2} \dot p_{C,z}
$$

$$
s_{i} = \Big(\mu_c - (\mu_c - \mu_s) \mathrm{exp} \left(-|\dot p_{C,i}|^2/v_s^2  \right) \Big)
$$

where $$ p_{C,i} $$, $$ i = x, y, z $$, are the $$ x - y - z $$ positions of the contact point; $$ F_{GRF,i} $$, $$ i = x, y, z $$, are the $$ x - y - z $$ components of the ground reaction force, assuming contact occurs between the robot and the ground substrate. The force terms are given by, $$ k_1 $$ and $$ k_2 $$ are the spring and damping coefficients of the compliant surface model. The term $$ s_i $$ is defined by $$ \mu_c $$, $$ \mu_s $$, and $$ \mu_v $$, which are the Coulomb, static, and viscous friction coefficients, with $$ v_s > 0 $$ being the Stribeck velocity. Specifically, the unknown parameters include actuator model parameters and Stribeck terms.

---

## Central Pattern Generators

Central Pattern Generators (CPGs) are neural networks in the spinal cord and brainstem of vertebrates, including humans, responsible for generating rhythmic neural activity that coordinates repetitive motor movements like walking, swimming, and breathing, without continuous input from higher brain centers. CPGs are crucial for locomotion and other rhythmic behaviors, producing rhythmic patterns even without sensory feedback or external stimuli. This autonomous rhythmicity allows for automatic and adaptive rhythmic movements without constant conscious control. 

In research and robotics, CPGs are studied for their potential in biomimetic control of locomotion and other behaviors in artificial systems. By modeling CPG principles in artificial neural networks, researchers can create control systems that mimic biological rhythmicity, integrating these artificial CPGs into robotic systems for autonomous and efficient control of locomotion, navigation, and other motor functions.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/joint_traj_robot.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 5: Signals generated from a simple sine wave CPG
</div>

## Modified Kuramoto Model

The Kuramoto CPG model is a mathematical framework for describing rhythmic oscillatory behavior in biological systems, particularly for robotic locomotion control, by using coupled phase oscillators to generate synchronized and coordinated rhythmic patterns. I used a modified version of the original Kuramoto model, with the dynamics detailed below.

$$
\dot{\varphi} = \omega + A \cdot \varphi + B \cdot \theta
$$

$$
\ddot{r} = a \cdot [\frac{a}{4} \cdot (R - r) - \dot{r}]
$$

$$
x = r \cdot \sin(\varphi) + \delta
$$

$$
A =
\begin{bmatrix}
-\mu_1 & \mu_1 \\
\mu_2 & -2\mu_2 & \mu_2 \\
 &  & \ddots &  \\
 &  & \mu_{n-1} & -2\mu_{n-1} & \mu_{n-1} \\
&  & & \mu_n & -\mu_n \\
\end{bmatrix}
$$

$$
B =
\begin{bmatrix}
1 \\
-1 & 1 \\
& -1 & \ddots \\
& & \ddots & 1 \\
& & & -1 & 1 \\
& & & & -1 \\
\end{bmatrix}
$$

Where $$\varphi \in \mathbb{R}^n$$ and $$r \in \mathbb{R}^n$$ are the internal states of the CPG, $$n$$ is the number of output channels (usually equal to the number of robot joints), $$a$$ and $$\mu_i$$ are hyperparameters controlling the convergence rate, $$R \in \mathbb{R}^n$$, $$\omega \in \mathbb{R}^n$$, $$\theta \in \mathbb{R}^{n-1}$$, $$\delta \in \mathbb{R}^n$$ are inputs controlling the desired amplitude, frequency, phase shift, and offset, and $$x \in \mathbb{R}^n$$ is the output sinusoidal waves of $$n$$ channels.

---
