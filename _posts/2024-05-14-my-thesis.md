---
layout: distill
title: Reinforcement Learning-Based Model Matching in COBRA, a Slithering Snake Robot
description: Here is a concise overview of the key ideas and findings from my thesis. Condensing a year's worth of brainstorming, programming, testing, reading, and writing into a single blog post is challenging, but I have done my best to capture the essence here.
giscus_comments: true
date: 2024-05-14
featured: true

bibliography: 2018-12-22-distill.bib

# Optionally, you can add a table of contents to your post.
# NOTES:
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
#   - we may want to automate TOC generation in the future using
#     jekyll-toc plugin (https://github.com/toshimaru/jekyll-toc).
toc:
  - name: Abstract
  - name: Introduction
    - name: Simulation-to-Reality Gap
        # if a section has subsections, you can add them as follows:
        # subsections:
        #   - name: Example Child Subsection 1
        #   - name: Example Child Subsection 2
    - name: Simulators and Physics Engines
    - name: Motivation

# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## Abstract

This work employs a reinforcement learning-based model identification method aimed at
enhancing the accuracy of the dynamics for our snake robot, called COBRA. Leveraging gradient
information and iterative optimization, the proposed approach refines the parameters of COBRA’s
dynamical model such as coefficient of friction and actuator parameters using experimental and
simulated data. Experimental validation on the hardware platform demonstrates the efficacy of the
proposed approach, highlighting its potential to address sim-to-real gap in robot implementation.

---

# Introduction

## Simualtion-to-Reality Gap

Developing effective locomotion controllers for mobile robots is challenging, and while Deep Reinforcement Learning (DRL) offers promising solutions, it requires impractical amounts of training data for high-risk tasks like locomotion and manipulation. Although computer simulations provide a safe and efficient training environment, the resulting policies often fail to transfer effectively to real hardware due to the "Simulation-to-Reality Gap" (sim2real gap), caused by discrepancies such as differences in friction, joint dynamics, and sensor noise between simulated and real environments. These discrepancies impede the transition of control policies from simulation to real-world applications, resulting in suboptimal performance and limited generalization of robotic systems.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/sim2real_methods_new.png" class="img-fluid rounded z-depth-1" zoomable=true width="70%" %}
    </div>
</div>
<div class="caption">
    Figure 1: Popular Solutions for Solving Sim2real Problem
</div>

To tackle the challenges of the Simulation-to-Reality Gap, recent research has focused on several advanced strategies. These include employing more sophisticated system identification procedures to improve model accuracy, training policies on real robots while simultaneously enhancing simulator accuracy through domain adaptation, and developing robust control policies that can generalize across varied simulated environments through domain randomization. Although these methods have shown good transferability of learned policies from simulation to real robots, they typically require at least 1000 hours of training in the simulator and/or hundreds of rollouts on the real robot. The figure below highlights several state-of-the-art solutions addressing the sim2real problem across various robots.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/sota.png" class="img-fluid rounded z-depth-1" zoomable=true width="70%" %}
    </div>
</div>
<div class="caption">
    Figure 2: Shows successful transfer of an RL-based policy on 1) ANYmal robot 2) & 6) Unitree A1 3) Hexapod 4) Cassie 5) Sirius 7) Mini Cheetah 8) 7-DoF Yumi Robot 9) & 13) ANYmal C 10) ANYmal B 11) Digit humanoid 12) Soft Snake Robot
</div>

---

## Simulators and Physics Engines

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/sim_table.png" class="img-fluid rounded z-depth-1" zoomable=true width="70%" %}
    </div>
</div>
<div class="caption">
    Table 1: Comparison of simulators
</div>

Table 1 compares pros and cons of most widely used physics simulators for robotics applications. After considering all the options, I chose the Webots simulator as the ideal platform for bridging the sim2real gap in training reinforcement learning (RL) agents for the COBRA platform due to its robust integration capabilities with RL training and extensive resources for developing locomotion, manipulation, and navigation controllers. Webots offers a user-friendly interface and supports various programming languages like Python and C++, simplifying the implementation and integration of RL algorithms. Its diverse library of robot models, realistic physics simulations, and advanced visualization tools create an optimal environment for training RL-based locomotion policies. Additionally, Webots provides comprehensive tools and resources for developing controllers for various tasks essential to the COBRA platform’s functionality. Overall, Webots’ compatibility with RL training and its rich resources make it an excellent choice for addressing the sim2real gap in developing efficient controllers for the COBRA platform.

---

## Motivation

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/research_gap.png" class="img-fluid rounded z-depth-1" zoomable=true width="70%" %}
    </div>
</div>
<div class="caption">
    Figure 3: Highlights the shared aspects among the popular solutions to sim2real problem
</div>

Significant progress has been made in simulation-to-reality transfer for locomotion tasks, but several research gaps remain. There is a strong motivation to develop a framework which:

1. is data-efficient
2. is learning-based
3. is scalable
4. is modular
5. requires minimum rollouts on the real robot
6. has standardized evaluation metrics for sim2real transfer

---
